// REQUIRES: TARGET-SM_90
// RUN: choreo -gs -t cute -arch=sm_90a %s -o %s.cute.result && CUDA_VISIBLE_DEVICES=1 CHOREO_DISABLE_TIMING=1 bash %s.cute.result --execute | FileCheck --match-full-lines %s && rm -f %s.cute.result

__co__ void matmul(global f8_e4m3 [M, K] lhs, global f8_e4m3 [N, K] rhs, global f32 [M, N] output) {
  int WARP_M = 64, WARP_N = 64, TILE_K = 32, WARP_K = 32;

  parallel {block_m, block_n} by [cdiv(M, WARP_M), cdiv(N, WARP_N)] : block {
    shared f8_e4m3 [WARP_M, TILE_K] lhs_load_s;
    shared f8_e4m3 [WARP_N, TILE_K] rhs_load_s;

    mc = mma.fill.f32 0.0f;
    foreach {iv_k} in [cdiv(K, TILE_K)] {
      tma.copy.swiz<32> lhs.subspan(WARP_M, TILE_K).step(WARP_M, TILE_K).at(block_m, iv_k) => lhs_load_s;

      tma.copy.swiz<32> rhs.chunkat(block_n, iv_k) => rhs_load_s;

      foreach {iv_warp} in [cdiv(TILE_K, WARP_K)] {
        parallel p by 1 : group-4 {
          ma = mma.load.swiz<32> lhs_load_s.chunkat(_, iv_warp);
          mb = mma.load.swiz<32> rhs_load_s.chunkat(_, iv_warp);
          mma.row.row mc, ma, mb;
        }
      }
    }

    shared f32 [WARP_M, WARP_N] output_s;
    mma.store mc, output_s;
    
    tma.copy output_s => output.subspan(WARP_M, WARP_N).step(WARP_M, WARP_N).at(block_m, block_n);
  }
}

int main(int argc, char** argv) {
  bool enable_timing = true;
  auto is_disable_timing_arg = [](const char* s) {
    const char* t = "--disable-timing";
    int i = 0;
    while (t[i] != '\0' && s[i] == t[i]) ++i;
    return t[i] == '\0' && s[i] == '\0';
  };
  for (int i = 1; i < argc; ++i) {
    if (is_disable_timing_arg(argv[i])) {
      enable_timing = false;
      break;
    }
  }

  const char* timing_env = std::getenv("CHOREO_DISABLE_TIMING");
  if (timing_env && timing_env[0] == '1' && timing_env[1] == '\0') {
    enable_timing = false;
  }

  size_t M = 768;
  size_t N = 512;
  size_t K = 512;

  auto lhs_h = choreo::make_spandata<choreo::f8_e4m3>(M, K);
  auto rhs_h = choreo::make_spandata<choreo::f8_e4m3>(N, K);
  auto res_h = choreo::make_spandata<float>(M, N);
  lhs_h.fill_random(0, 2);
  rhs_h.fill_random(0, 2);
  res_h.fill(0.0f);

  __nv_fp8_e4m3 *a_d = nullptr;
  __nv_fp8_e4m3 *b_d = nullptr;
  float *c_d = nullptr;
  cudaMalloc(&a_d, M * K * sizeof(__nv_fp8_e4m3));
  cudaMalloc(&b_d, N * K * sizeof(__nv_fp8_e4m3));
  cudaMalloc(&c_d, M * N * sizeof(float));

  cudaMemcpy(a_d, lhs_h.data(), M * K * sizeof(__nv_fp8_e4m3), cudaMemcpyHostToDevice);
  cudaMemcpy(b_d, rhs_h.data(), N * K * sizeof(__nv_fp8_e4m3), cudaMemcpyHostToDevice);
  cudaMemcpy(c_d, res_h.data(), M * N * sizeof(float), cudaMemcpyHostToDevice);

  auto lhs_d = choreo::make_spanview<choreo::f8_e4m3, 2>(a_d, {M, K});
  auto rhs_d = choreo::make_spanview<choreo::f8_e4m3, 2>(b_d, {N, K});
  auto res_d = choreo::make_spanview<float, 2>(c_d, {M, N});

  if (enable_timing) {
    choreo::TimerOption topt;
    topt.warmup = 10;
    topt.repeat = 50;
    auto avg_ms = choreo::timing([&]() { matmul(lhs_d, rhs_d, res_d); cudaDeviceSynchronize(); }, topt);
    std::cout << "Timing avg ms: " << avg_ms << "\n";
  } else {
    matmul(lhs_d, rhs_d, res_d);
  }

  cudaMemcpy(res_h.data(), c_d, M * N * sizeof(float), cudaMemcpyDeviceToHost);

  auto lhs_view = lhs_h.view();
  auto rhs_view = rhs_h.view();
  auto res_view = res_h.view();

  float base_tol = 0.3f;
  float rel_tol = 0.05f;
  choreo::verify_matmul_row_row_subset(lhs_h, rhs_h, res_h, base_tol, rel_tol, 8, 8);
  std::cout << "Test Passed\n" << std::endl;
}
// CHECK: Test Passed
